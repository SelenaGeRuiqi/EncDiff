#!/usr/bin/env python
"""
ä¸ºå¤šä¸ªå®éªŒçš„æ‰€æœ‰ checkpoints ç”Ÿæˆ swap å¯è§†åŒ–å›¾ç‰‡

è¾“å…¥: å®éªŒç›®å½•åˆ—è¡¨
å¯¹äºæ¯ä¸ªå®éªŒç›®å½•:
  - æ‰¾åˆ° checkpoints/ ä¸‹æ‰€æœ‰ checkpoint æ–‡ä»¶
  - æ ¹æ®å®éªŒåå­—åˆ¤æ–­æ•°æ®é›†ç±»å‹ (shapes3d, cars3d, mpi3d)
  - ä¸ºæ¯ä¸ª checkpoint ç”Ÿæˆ swap å¯è§†åŒ–
  - ä¿å­˜åˆ° swap_images_{checkpointåå­—}/ æ–‡ä»¶å¤¹
"""
import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import sys
import os
import glob

sys.path.append('/mnt/data_7tb/selena/projects/EncDiff')

from ldm.util import instantiate_from_config
from omegaconf import OmegaConf
from ldm.data.disdata import Shapes3DTrain, Cars3DTrain, MPI3DTrain
from torchvision.utils import make_grid


# ============================================================================
# å®éªŒç›®å½•åˆ—è¡¨
# ============================================================================
EXPERIMENT_DIRS = [
    '/mnt/data_7tb/selena/projects/EncDiff/logs/2026-01-04T09-59-07_shapes3d-vq-4-16-encdiff23',
    '/mnt/data_7tb/selena/projects/EncDiff/logs/2026-01-05T01-46-21_cars3d-vq-4-16-encdiff23',
    '/mnt/data_7tb/selena/projects/EncDiff/logs/2026-01-05T06-14-44_mpi3d-vq-4-16-encdiff23',
    '/mnt/data_7tb/selena/projects/EncDiff/logs/2026-01-10T07-42-42_shapes3d-vq-4-16-encdiff23',
    '/mnt/data_7tb/selena/projects/EncDiff/logs/2026-01-10T08-23-34_mpi3d-vq-4-16-encdiff23',
    '/mnt/data_7tb/selena/projects/EncDiff/logs/2026-01-10T08-25-57_cars3d-vq-4-16-encdiff23',
]

def get_dataset_type(exp_dir):
    """æ ¹æ®å®éªŒç›®å½•ååˆ¤æ–­æ•°æ®é›†ç±»å‹"""
    exp_name = os.path.basename(exp_dir).lower()
    if 'shapes3d' in exp_name:
        return 'shapes3d'
    elif 'cars3d' in exp_name:
        return 'cars3d'
    elif 'mpi3d' in exp_name:
        return 'mpi3d'
    else:
        raise ValueError(f"Unknown dataset type from exp_dir: {exp_dir}")


def get_config_path_from_exp_dir(exp_dir):
    """ä»å®éªŒç›®å½•ä¸­è·å–ä¿å­˜çš„é…ç½®æ–‡ä»¶è·¯å¾„"""
    configs_dir = os.path.join(exp_dir, 'configs')
    if not os.path.exists(configs_dir):
        raise ValueError(f"Configs directory not found: {configs_dir}")
    
    # æŸ¥æ‰¾ *-project.yaml æ–‡ä»¶
    project_yamls = glob.glob(os.path.join(configs_dir, '*-project.yaml'))
    if not project_yamls:
        raise ValueError(f"No project.yaml found in: {configs_dir}")
    
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸åªæœ‰ä¸€ä¸ªï¼Œæˆ–å–æœ€æ—©çš„ï¼‰
    project_yamls = sorted(project_yamls)
    return project_yamls[0]


def get_dataset(dataset_type):
    """è·å–æ•°æ®é›†å®ä¾‹"""
    dataset_map = {
        'shapes3d': Shapes3DTrain,
        'cars3d': Cars3DTrain,
        'mpi3d': MPI3DTrain,
    }
    return dataset_map[dataset_type]()


def load_model(config_path, ckpt_path):
    """åŠ è½½æ¨¡å‹"""
    config = OmegaConf.load(config_path)
    model = instantiate_from_config(config.model)
    
    ckpt = torch.load(ckpt_path, map_location='cpu')
    model.load_state_dict(ckpt['state_dict'], strict=False)
    model.eval()
    model = model.cuda()
    return model, config


def generate_swap_visualization(model, dataset, output_path, n_samples=8, ddim_steps=200):
    """
    ç”Ÿæˆ swap å¯è§†åŒ–å›¾ç‰‡
    
    Args:
        model: åŠ è½½çš„æ¨¡å‹
        dataset: æ•°æ®é›†
        output_path: è¾“å‡ºè·¯å¾„
        n_samples: æ¯æ¬¡ç”Ÿæˆçš„æ ·æœ¬æ•°
        ddim_steps: DDIM é‡‡æ ·æ­¥æ•°
    """
    print(f"      Generating swap visualization...")
    
    # éšæœºé€‰æ‹©æ ·æœ¬
    np.random.seed(42)
    indices = np.random.choice(len(dataset), n_samples, replace=False)
    
    images = []
    for idx in indices:
        sample = dataset[idx]
        if torch.is_tensor(sample['image']):
            img = sample['image']
        else:
            img = torch.from_numpy(sample['image']).float()
        images.append(img)
    
    batch_images = torch.stack(images, dim=0).cuda()  # (n_samples, H, W, C)
    batch_dict = {'image': batch_images}
    
    # è°ƒç”¨ log_images ç”Ÿæˆ swap æ ·æœ¬
    with torch.no_grad():
        log = model.log_images(
            batch_dict,
            N=n_samples,
            sample_swap=True,
            ddim_steps=ddim_steps,
            ddim_eta=0.0,
            inpaint=False,
            plot_progressive_rows=False,
            plot_diffusion_rows=False
        )
    
    # ä¿å­˜åŸå§‹è¾“å…¥
    if 'inputs' in log:
        inputs = log['inputs']
        grid = make_grid(inputs, nrow=4)
        grid = (grid + 1) / 2  # normalize to [0,1]
        grid = grid.permute(1, 2, 0).cpu().numpy()
        grid = np.clip(grid, 0, 1)
        
        input_path = output_path.replace('.png', '_inputs.png')
        Image.fromarray((grid * 255).astype(np.uint8)).save(input_path)
    
    # ä¿å­˜ swap ç»“æœ
    if 'samples_swapping' in log:
        swapping = log['samples_swapping']
        latent_unit = model.model.diffusion_model.latent_unit
        
        # ä¿å­˜å®Œæ•´çš„ swap grid
        grid = make_grid(swapping, nrow=n_samples)
        grid = (grid + 1) / 2
        grid = grid.permute(1, 2, 0).cpu().numpy()
        grid = np.clip(grid, 0, 1)
        
        Image.fromarray((grid * 255).astype(np.uint8)).save(output_path)
        
        # åˆ›å»ºå¸¦æ ‡ç­¾çš„å¯è§†åŒ–
        create_labeled_visualization(
            log['inputs'].cpu(),
            swapping.cpu(),
            latent_unit,
            n_samples,
            output_path.replace('.png', '_labeled.png')
        )
    
    return log


def create_labeled_visualization(inputs, swapping, latent_unit, n_samples, output_path, 
                                  factors_per_page=10):
    """
    åˆ›å»ºå¸¦æ ‡ç­¾çš„å¯è§†åŒ–ï¼Œæ–¹ä¾¿åˆ†ææ¯ä¸ª factor
    
    å›¾ç‰‡å¸ƒå±€ï¼š
    - ç¬¬ä¸€è¡Œ: åŸå§‹è¾“å…¥å›¾ç‰‡
    - åç»­æ¯è¡Œ: swap ç¬¬ i ä¸ª latent unit åçš„ç»“æœ
    """
    
    # åˆ†é¡µæ˜¾ç¤º
    n_pages = (latent_unit + factors_per_page - 1) // factors_per_page
    
    for page in range(n_pages):
        start_factor = page * factors_per_page
        end_factor = min((page + 1) * factors_per_page, latent_unit)
        n_factors_this_page = end_factor - start_factor
        
        fig, axes = plt.subplots(n_factors_this_page + 1, n_samples, 
                                figsize=(2*n_samples, 2*(n_factors_this_page+1)))
        
        # ç¬¬ä¸€è¡Œï¼šåŸå§‹è¾“å…¥
        for i in range(n_samples):
            img = inputs[i].permute(1, 2, 0).numpy()
            img = (img + 1) / 2
            img = np.clip(img, 0, 1)
            axes[0, i].imshow(img)
            axes[0, i].axis('off')
            if i == 0:
                axes[0, i].set_ylabel('Input', fontsize=10, rotation=0, ha='right', labelpad=30)
        
        # åç»­æ¯è¡Œï¼šswap åçš„ç»“æœ
        for factor_idx in range(start_factor, end_factor):
            row_idx = factor_idx - start_factor + 1
            for sample_idx in range(n_samples):
                img_idx = factor_idx * n_samples + sample_idx
                img = swapping[img_idx].permute(1, 2, 0).numpy()
                img = (img + 1) / 2
                img = np.clip(img, 0, 1)
                axes[row_idx, sample_idx].imshow(img)
                axes[row_idx, sample_idx].axis('off')
                
            axes[row_idx, 0].set_ylabel(f'Factor {factor_idx}', fontsize=10, 
                                        rotation=0, ha='right', labelpad=30)
        
        plt.tight_layout()
        page_path = output_path.replace('.png', f'_page{page+1}.png')
        plt.savefig(page_path, dpi=150, bbox_inches='tight')
        plt.close()


def process_experiment(exp_dir):
    """å¤„ç†å•ä¸ªå®éªŒç›®å½•"""
    print(f"\n{'='*70}")
    print(f"ğŸ“ Processing: {exp_dir}")
    print(f"{'='*70}")
    
    # åˆ¤æ–­æ•°æ®é›†ç±»å‹
    dataset_type = get_dataset_type(exp_dir)
    print(f"   Dataset type: {dataset_type}")
    
    # ä»å®éªŒç›®å½•è·å–ä¿å­˜çš„é…ç½®æ–‡ä»¶ï¼ˆè¿™æ ·å¯ä»¥ç¡®ä¿æ¨¡å‹ç»“æ„åŒ¹é…ï¼‰
    config_path = get_config_path_from_exp_dir(exp_dir)
    print(f"   Config: {config_path}")
    
    # åŠ è½½æ•°æ®é›†ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
    print(f"   Loading dataset...")
    dataset = get_dataset(dataset_type)
    print(f"   Dataset size: {len(dataset)}")
    
    # è·å–æ‰€æœ‰ checkpoint æ–‡ä»¶
    ckpt_dir = os.path.join(exp_dir, 'checkpoints')
    ckpt_files = glob.glob(os.path.join(ckpt_dir, '*.ckpt'))
    ckpt_files = sorted(ckpt_files)
    
    print(f"   Found {len(ckpt_files)} checkpoints:")
    for ckpt_file in ckpt_files:
        print(f"      - {os.path.basename(ckpt_file)}")
    
    # ä¸ºæ¯ä¸ª checkpoint ç”Ÿæˆå¯è§†åŒ–
    for ckpt_path in ckpt_files:
        ckpt_name = os.path.basename(ckpt_path).replace('.ckpt', '')
        output_dir = os.path.join(exp_dir, f'swap_images_{ckpt_name}')
        
        # æ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å·²å­˜åœ¨ä¸”éç©ºï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡
        if os.path.exists(output_dir) and os.listdir(output_dir):
            print(f"\n   â­ï¸  Skipping checkpoint: {ckpt_name} (output dir not empty)")
            continue
        
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"\n   ğŸ“¦ Processing checkpoint: {ckpt_name}")
        print(f"      Output dir: {output_dir}")
        
        try:
            # åŠ è½½æ¨¡å‹
            print(f"      Loading model...")
            model, config = load_model(config_path, ckpt_path)
            
            # ç”Ÿæˆå¯è§†åŒ–
            output_path = os.path.join(output_dir, 'swap_visualization.png')
            generate_swap_visualization(
                model,
                dataset,
                output_path,
                n_samples=8,
                ddim_steps=200
            )
            
            print(f"      âœ… Done: {output_dir}")
            
            # é‡Šæ”¾ GPU å†…å­˜
            del model
            torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"      âŒ Error: {e}")
            import traceback
            traceback.print_exc()
            continue


def main():
    print("=" * 70)
    print("ğŸ¨ Generate Swap Visualization for All Checkpoints")
    print("=" * 70)
    
    print(f"\nExperiment directories to process: {len(EXPERIMENT_DIRS)}")
    for exp_dir in EXPERIMENT_DIRS:
        print(f"   - {exp_dir}")
    
    # å¤„ç†æ¯ä¸ªå®éªŒ
    for exp_dir in EXPERIMENT_DIRS:
        if os.path.exists(exp_dir):
            process_experiment(exp_dir)
        else:
            print(f"\nâš ï¸ Directory not found: {exp_dir}")
    
    print("\n" + "=" * 70)
    print("âœ… All done!")
    print("=" * 70)


if __name__ == "__main__":
    main()
